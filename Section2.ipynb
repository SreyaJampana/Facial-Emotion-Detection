{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SreyaJampana/Facial-Emotion-Detection/blob/main/Section2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "H1K_OUCXfPzH",
        "outputId": "91f3df48-f45d-4bb2-ce84-7e57f5db2442"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "./ferdata.csv       100%[===================>] 159.97M  61.6MB/s    in 2.6s    \n",
            "./shape_predictor_6 100%[===================>]  95.08M  74.3MB/s    in 1.3s    \n",
            "./pureX.npy         100%[===================>]  43.95M  52.3MB/s    in 0.8s    \n",
            "./dataX.npy         100%[===================>] 347.59M  75.3MB/s    in 5.5s    \n",
            "./dataY.npy         100%[===================>] 156.38K  --.-KB/s    in 0.002s  \n",
            "Data Downloaded!\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import dlib\n",
        "import gdown\n",
        "import pickle\n",
        "import warnings\n",
        "import itertools\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "import urllib.request\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from scipy.spatial import distance\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "###Getting the csv data loaded\n",
        "!wget -q --show-progress -O ./ferdata.csv \"https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Emotion%20Detection/fer2013_5.csv\"\n",
        "\n",
        "###Getting the Dlib Shape predictor!\n",
        "!wget -q --show-progress -O ./shape_predictor_68_face_landmarks.dat \"https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Emotion%20Detection/shape_predictor_68_face_landmarks.dat\"\n",
        "\n",
        "###Getting the Xpure loaded\n",
        "!wget -q --show-progress -O ./pureX.npy \"https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Emotion%20Detection/pureX.npy\"\n",
        "\n",
        "###Getting the Xdata loaded\n",
        "!wget -q --show-progress -O ./dataX.npy \"https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Emotion%20Detection/dataX.npy\"\n",
        "\n",
        "###Getting the Ydata loaded\n",
        "!wget -q --show-progress -O ./dataY.npy \"https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Emotion%20Detection/dataY.npy\"\n",
        "\n",
        "print (\"Data Downloaded!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtHdXOQqF_kA"
      },
      "source": [
        "#Milestone 1: Understanding the Feature Generation Process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dqw7wKpPSCUR"
      },
      "source": [
        "##Distance between Facial Landmarks\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNRbQK8A25Zu"
      },
      "source": [
        "Distances measured between specific facial landmarks can serve as valuable input features (X) for a predictive model. In this model, these features are analyzed to determine the corresponding facial expressions or emotions, which are the outputs (Y). By feeding these calculated distances into the model, it can effectively learn to associate particular patterns of facial landmark distances with specific emotional states.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bg16jaZu7vF"
      },
      "outputs": [],
      "source": [
        "#Integer to Label Mapping\n",
        "label_map = {0:\"ANGRY\",1:\"HAPPY\",2:\"SAD\",3:\"SURPRISE\",4:\"NEUTRAL\"}\n",
        "\n",
        "#Load the data\n",
        "df = pd.read_csv(\"./ferdata.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emNk3kn7-SWh"
      },
      "outputs": [],
      "source": [
        "# generate x labels for our plot\n",
        "emotion_labels = [label_map[i] for i in label_map.keys()]\n",
        "\n",
        "# generate counts for each emotion type\n",
        "emotion_counts = [np.sum(df[\"emotion\"] == i) for i in range(len(label_map))]\n",
        "\n",
        "# generate a bar plot for our emotion labels that has different colors\n",
        "[plt.bar(x = emotion_labels[i], height = emotion_counts[i] ) for i in range(len(emotion_labels))]\n",
        "\n",
        "# make the plot interpretable with x and y labels + title\n",
        "plt.xlabel('EMOTION LABEL')\n",
        "plt.ylabel('N OBSERVSATIONS')\n",
        "plt.title('A balanced distribution of emotions in our data set', y=1.05);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTkynlyy75cm"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load's dlib's pretrained face detector model\n",
        "#frontalface_detector = dlib.get_frontal_face_detector()\n",
        "\n",
        "\n",
        "#Load the 68 face Landmark file\n",
        "predictor = dlib.shape_predictor('./shape_predictor_68_face_landmarks.dat')\n",
        "\"\"\"\n",
        "Returns facial landmarks for the given input image path\n",
        "\"\"\"\n",
        "def get_landmarks(image):\n",
        "\n",
        "\n",
        "  #:type image : cv2 object\n",
        "  #:rtype landmarks : list of tuples where each tuple represents\n",
        "  #                  the x and y co-ordinates of facial keypoints\n",
        "\n",
        "  #Bounding Box co-ordinates around the face(Training data is 48*48(cropped faces))\n",
        "  rects = [dlib.rectangle(left=1, top=1, right=47, bottom=47)]\n",
        "\n",
        "  #Read Image using OpenCV\n",
        "  #image = cv2.imread(image_path)\n",
        "  #Detect the Faces within the image\n",
        "  landmarks = [(p.x, p.y) for p in predictor(image, rects[0]).parts()]\n",
        "  return image,landmarks\n",
        "\n",
        "\"\"\"\n",
        "Display image with its Facial Landmarks\n",
        "\"\"\"\n",
        "def plot_image_landmarks(image,face_landmarks):\n",
        "  \"\"\"\n",
        "  :type image_path : str\n",
        "  :type face_landmarks : list of tuples where each tuple represents\n",
        "                     the x and y co-ordinates of facial keypoints\n",
        "  :rtype : None\n",
        "  \"\"\"\n",
        "  radius = -2\n",
        "  circle_thickness = 1\n",
        "  image_copy = image.copy()\n",
        "  for (x, y) in face_landmarks:\n",
        "    cv2.circle(image_copy, (x, y), circle_thickness, (255,0,0), radius)\n",
        "\n",
        "  plt.imshow(image_copy, interpolation='nearest', cmap='Greys_r')\n",
        "  plt.xticks([]); plt.yticks([])\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "'''\n",
        "Converts pixels values to 2D-image.\n",
        "Displays the image and returns the cv2 image\n",
        "object\n",
        "'''\n",
        "def get_pixels_image(img_pixels,plt_flag):\n",
        "  \"\"\"\n",
        "  :type image_pixels : str\n",
        "  :type plt_flag : boolean\n",
        "  :rtype image : cv2 object\n",
        "  \"\"\"\n",
        "\n",
        "  width = 48\n",
        "  height = 48\n",
        "\n",
        "  image = np.fromstring(img_pixels, dtype=np.uint8, sep=\" \").reshape((height, width))\n",
        "\n",
        "  if plt_flag:\n",
        "      plt.imshow(image, interpolation='nearest', cmap=\"Greys_r\")\n",
        "      plt.xticks([]); plt.yticks([])\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "  return image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6kqtTORlAZ3"
      },
      "outputs": [],
      "source": [
        "# select random index\n",
        "i_index = np.random.randint(len(df))\n",
        "\n",
        "# extract pixel values\n",
        "image_pixels = df['pixels'][i_index]\n",
        "\n",
        "# convert pixels to 2D Images\n",
        "image = get_pixels_image(image_pixels, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLcpEqE_-w-T"
      },
      "outputs": [],
      "source": [
        "#Extract the Facial Landmarks\n",
        "image,facial_landmarks = get_landmarks(image)\n",
        "\n",
        "#Display the Facial Landmarks on the Image\n",
        "plot_image_landmarks(image,facial_landmarks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "To9kDuP0IXsV"
      },
      "outputs": [],
      "source": [
        "for i, j in itertools.combinations(range(4), 2):\n",
        "  print(i, j)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AblhKSuIZufy"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Computes euclidean distance between 68 Landmark Points for our features\n",
        "e_dist is a list of features that will go into our model.\n",
        "Each feature is a distance between two landmark points, and every pair of points\n",
        "must have a feature.\n",
        "Scipy Library has readily available fuction to compute euclidean distance. You can\n",
        "compute the distance using distance.euclidean(point1,point2)\n",
        "point1,point2 :2D points\n",
        "\"\"\"\n",
        "def get_all_landmarks_euclid_dist(face_landmarks):\n",
        "\n",
        "    e_dist = []\n",
        "    # FILL ME IN!\n",
        "    # Use this to get the distance between two points:\n",
        "    #               distance.euclidean(face_landmarks[i],face_landmarks[j])\n",
        "\n",
        "    return e_dist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Im_3G3gtaqsK"
      },
      "outputs": [],
      "source": [
        "\n",
        "def preprocess_data(df):\n",
        "\n",
        "  X = []\n",
        "  Y = []\n",
        "  X_pixels = []\n",
        "\n",
        "  n_pixels = 2304\n",
        "\n",
        "  for index, row in (df.iterrows()):\n",
        "\n",
        "      if index%1000 == 0:\n",
        "        print (index, \"Datapoints Processed\")\n",
        "\n",
        "      try:\n",
        "          image = get_pixels_image(row['pixels'],0)\n",
        "          X_pixels.append(image.ravel())\n",
        "          image = cv2.GaussianBlur(image,(5,5),0)\n",
        "\n",
        "          _,face_landmarks = get_landmarks(image)\n",
        "          X.append(get_all_landmarks_euclid_dist(face_landmarks)) # Using our feature function!\n",
        "          Y.append(row['emotion'])\n",
        "\n",
        "      except Exception as e:\n",
        "          print (\"An error occured:\",e)\n",
        "\n",
        "  #Save the data\n",
        "  np.save(\"pureX\", X_pixels)\n",
        "  np.save(\"dataX\", X)\n",
        "  np.save(\"dataY\", Y)\n",
        "\n",
        "  return np.array(X_pixels),np.array(X),np.array(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cypubed0HIBt"
      },
      "outputs": [],
      "source": [
        "# set to True if we want to preload data -- which has already been generated for us :)\n",
        "preload = True\n",
        "\n",
        "if preload:\n",
        "\n",
        "  # load outputs saved in this folder after running preprocess_data()\n",
        "  dataX = np.load('./dataX.npy')\n",
        "  dataY = np.load('./dataY.npy', allow_pickle=True)\n",
        "\n",
        "else:\n",
        "\n",
        "  # this takes 15-20 minutes to run, but someone has already run it and saved the ouputs in this folder\n",
        "  pureX, dataX, dataY = preprocess_data(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cAC2tMjwK34"
      },
      "outputs": [],
      "source": [
        "#Split Data into Train, Test (90-10)\n",
        "X_train, X_test, y_train, y_test = train_test_split(dataX, dataY, test_size=0.1, random_state=42,stratify =dataY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-y3gscsW3IC"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train,y_train)\n",
        "model.score(X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctD2nHn1wKFA"
      },
      "outputs": [],
      "source": [
        "####Standardize the data####################\n",
        "###Note: Do not use test data to fit your Standardscaler Model\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgzUfFcdPIkr"
      },
      "outputs": [],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SV0jORxMH3w1"
      },
      "source": [
        "#Milestone 3 : Applying Machine Learning to Emotion Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swvm8N2Xra2t"
      },
      "outputs": [],
      "source": [
        "\n",
        "#######Train the model##################\n",
        "knn = KNeighborsClassifier(n_neighbors=10)\n",
        "print (\"Training the knn model\")\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "#######Evaluate the model##################\n",
        "# they might use accuracy_score\n",
        "#This cell will take longer to run(5-10mins)!\n",
        "print (\"Predict for KNN Model\")\n",
        "y_predknn = knn.predict(X_test)\n",
        "print (\"Prediction Completed\")\n",
        "print (\"Test Accuracy(KNN):\",metrics.accuracy_score(y_test, y_predknn))\n",
        "\n",
        "#-----------------DecisionTreeClassifier--------------#\n",
        "#######Train the model##################\n",
        "dt = DecisionTreeClassifier(max_depth=20)\n",
        "print (\"Training the Decision Tree model\")\n",
        "dt.fit(X_train, y_train)\n",
        "print (\"Completed Decision Tree Training\")\n",
        "\n",
        "#######Evaluate the model##################\n",
        "\n",
        "print (\"Predict for Decision Tree Model\")\n",
        "y_preddt = dt.predict(X_test)\n",
        "print (\"Test Accuracy(DT):\",metrics.accuracy_score(y_test, y_preddt))\n",
        "\n",
        "\n",
        "#-----------------Logistic Regression--------------#\n",
        "#######Train the model##################\n",
        "lr = LogisticRegression(solver='lbfgs',multi_class='multinomial')\n",
        "print (\"Training the Logistic Regression model\")\n",
        "lr.fit(X_train, y_train)\n",
        "print (\"Completed LR Training\")\n",
        "\n",
        "#######Evaluate the model##################\n",
        "# they might use accuracy_score\n",
        "#This cell will take longer to run(5-10mins)!\n",
        "print (\"Predict for LR Model\")\n",
        "y_predlr = lr.predict(X_test)\n",
        "print (\"Test Accuracy(LR):\",metrics.accuracy_score(y_test, y_predlr))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eN0uVF7cwbGk"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Plots the confusion Matrix and saves it\n",
        "Pass the true labels and the predicted labels\n",
        "'''\n",
        "def plot_confusion_matrix(y_true,y_predicted):\n",
        "  cm = metrics.confusion_matrix(y_true, y_predicted)\n",
        "  print (\"Plotting the Confusion Matrix\")\n",
        "  labels = list(label_map.values())\n",
        "  df_cm = pd.DataFrame(cm,index = labels,columns = labels)\n",
        "  fig = plt.figure()\n",
        "  res = sns.heatmap(df_cm, annot=True,cmap='Blues', fmt='g')\n",
        "  plt.yticks([0.5,1.5,2.5,3.5,4.5], labels,va='center')\n",
        "  plt.title('Confusion Matrix - TestData')\n",
        "  plt.ylabel('True label')\n",
        "  plt.xlabel('Predicted label')\n",
        "  plt.show()\n",
        "  plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpKyqmW8_4LF"
      },
      "outputs": [],
      "source": [
        "plot_confusion_matrix(\n",
        "        y_test, y_predlr\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0dNBYIPI2-c"
      },
      "source": [
        "#Milestone 4: Coding Exercise\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqMKoYD0Ib9L"
      },
      "outputs": [],
      "source": [
        "#Load the true pixel data and corresponding labels\n",
        "X = np.load('pureX.npy')\n",
        "Y = np.load('dataY.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_8Mo7OOrz6g"
      },
      "outputs": [],
      "source": [
        "#Split Data into Train, Test (90-10)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=42,stratify =Y)\n",
        "\n",
        "\n",
        "#Standardize the Data\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "#######Train the model##################\n",
        "knn = KNeighborsClassifier(n_neighbors=10)\n",
        "print (\"Training the knn model\")\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "#######Evaluate the model##################\n",
        "# they might use accuracy_score\n",
        "#This cell will take longer to run(5-10mins)!\n",
        "print (\"Predict for KNN Model\")\n",
        "y_predknn = knn.predict(X_test)\n",
        "print (\"Prediction Completed\")\n",
        "print (\"Test Accuracy(KNN):\",metrics.accuracy_score(y_test, y_predknn))\n",
        "\n",
        "\n",
        "\n",
        "#-----------------DecisionTreeClassifier--------------#\n",
        "#######Train the model##################\n",
        "dt = DecisionTreeClassifier(max_depth=20)\n",
        "print (\"Training the Decision Tree model\")\n",
        "dt.fit(X_train, y_train)\n",
        "print (\"Completed Decision Tree Training\")\n",
        "\n",
        "#######Evaluate the model##################\n",
        "\n",
        "print (\"Predict for Decision Tree Model\")\n",
        "y_preddt = dt.predict(X_test)\n",
        "print (\"Test Accuracy(DT):\",metrics.accuracy_score(y_test, y_preddt))\n",
        "\n",
        "\n",
        "#-----------------Logistic Regression--------------#\n",
        "#######Train the model##################\n",
        "lr = LogisticRegression(solver='lbfgs',multi_class='multinomial')\n",
        "print (\"Training the Logistic Regression model\")\n",
        "lr.fit(X_train, y_train)\n",
        "print (\"Completed LR Training\")\n",
        "\n",
        "#######Evaluate the model##################\n",
        "# they might use accuracy_score\n",
        "#This cell will take longer to run(5-10mins)!\n",
        "print (\"Predict for LR Model\")\n",
        "y_predlr = lr.predict(X_test)\n",
        "print (\"Test Accuracy(LR):\",metrics.accuracy_score(y_test, y_predlr))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fnDYz09W36xG"
      },
      "outputs": [],
      "source": [
        "from joblib import dump\n",
        "dump(MODEL_VARIABLE, \"MODEL_NAME.joblib\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}